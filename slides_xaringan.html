<!DOCTYPE html>
<html>
  <head>
    <title>Estadística Bayesiana y Programación Probabilística</title>
    <meta charset="utf-8">
    <meta name="author" content="Adolfo Martínez" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
    <link rel="stylesheet" href="portada.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Estadística Bayesiana y Programación Probabilística
## O cómo dejé de preocuparme y aprendí a amar la incertidumbre
### Adolfo Martínez
### 2017/03/28

---




## Reducir Incertidumbre

Históricamente:

- Oráculos
- Religión
- Empirismo
- Método Científico
- Análisis de Datos

---
class: middle, center, inverse
## Estadística Frecuentista

---
## Estadística Frecuentista

Históricamente desarrollada a partir del estudio de **frecuencias**. Toma éstas como medida objetiva de la realidad y aproximación de la **probabilidad** "real"

- Prueba (contraste) de hipótesis
- Diseño de experimentos
- Predicción

---
background-image: url(resources/uniqueevent.png)
background-size: 500px
background-position: 50% 70%

## Estadística Frecuentista 
### Algunos problemas


Probabilidad de eventos únicos y cantidades fijas pero desconocidas

---
background-image: url(resources/test.gif)
background-size: 350px
background-position: 50% 70%

## Estadística Frecuentista 
### Algunos problemas

Técnicas con fundamento teórico débil (*e.g.* valores p)

* Juzga `\(H\)` basado en `\(P(D|H)\)`

---
class: middle, center, inverse
## Machine Learning

---
## Machine Learning

Estudio y construcción de algoritmos que **aprenden** y realizan **predicciones** basados en datos

- Predicción
- Clustering
- Minado de Reglas

---
## Machine Learning 
### Algunos problemas

Responden una pregunta específica

* Por ejemplo, estimar una respuesta `\(y\)` dados los datos `\(X\)`, *i.e.* `\(y = \hat{f}(x)\)`
* Bajo pérdida cuadrática: `\(\hat{f}(x) = E[Y | X = x]\)`
* `\(P(Y | X = x) &gt; \alpha\)`
* En muchos algoritmos, no hay una respuesta inmediata a esta pregunta 

---
background-image: url(resources/mlp.png)
background-size: 500px
background-position: 50% 70%

## Machine Learning 
### Algunos problemas

Dificultad en la interpretación

---
background-image: url(resources/notagorilla.png)
background-size: 400px
background-position: 50% 70%
## Machine Learning 
### Algunos problemas

Sobrecertidumbre

---
class: middle, center, inverse
## Estadística Bayesiana

---
## Estadística Bayesiana

Incorpora la **incertidumbre** subjetiva o **creencias inciales** como información previa a la inferencia. La **probabilidad** es una medida de incertidumbre, no una frecuencia

- Prueba (contraste) de hipótesis
- Diseño de experimentos
- Predicción

---
## Estadística Bayesiana 
### vs. Frecuentismo

Tiene una manera clara y bien fundamentada de asignar probabilidad a eventos únicos o cantidades desconocidas

&lt;center&gt; `$$P(\theta|D) \propto P(D|\theta)P(\theta)$$` &lt;/center&gt;

* `\(P(\theta)\)` se obtiene de las creencias iniciales (*a priori*)
* De no existir, se pueden usar *a priori* no informativas

---
background-image: url(resources/posterior.png)
background-size: 500px
background-position: 50% 75%
## Estadística Bayesiana 
### vs. Frecuentismo

Tiene una manera clara y bien fundamentada de calcular la probabilidad de una hipótesis

* Juzga `\(H\)` basado en `\(P(H|D)\)`


---
## Estadística Bayesiana 
### vs. Machine Learning

Puede resolver una gran cantidad de preguntas acerca de la variable de respuesta

&lt;img src="slides_xaringan_files/figure-html/predictiva-1.png" style="display: block; margin: auto;" /&gt;

El área sombreada representa `\(P(0 &lt; \tilde{y} &lt; 2.5 | \tilde{x}, X, \theta)\)`

---
## Estadística Bayesiana 
### vs. Machine Learning

Como la Frecuentista, los modelos básicos son fácilmente interpretables

- Por ejemplo, en un modelo lineal bayesiano, las posteriores de los coeficientes `\(\beta_i\)`, describen la incertidumbre acerca de su valor

&lt;img src="slides_xaringan_files/figure-html/posteriores-1.png" style="display: block; margin: auto;" /&gt;

---
## Estadística Bayesiana 
### vs. Machine Learning

La incertidumbre se conserva en cada paso de la inferencia

* Por ejemplo, terminada la inferencia podemos calcular la probabilidad de que los parámetros sean cercanos a `\(0\)`
* O bien, además del estimado puntual, calcular un intervalo de **probabilidad** para `\(Y\)`
* Conservar y conocer esta incertidumbre nos permite tomar mejores decisiones al predecir (por ejemplo, elegir no hacerlo)

---
## Estadística Bayesiana 
### Algunos problemas

### Cálculo de la posterior - Dificultad Matemática

* Para calcular la posterior de manera exacta, necesitamos resolver: `\(P(D) = \int_{\theta}P(D|\theta)P(\theta)d\theta\)`
* La distribución predictiva se obtiene a través de una integral similar: `\(P(\tilde{y} | \tilde{x}, \theta, D) = \int_{\theta}P(\tilde{y}|\tilde{x},\theta)P(\theta|D)d\theta\)`
* Estos problemas no siempre tienen una solución analítica

---
## Estadística Bayesiana 
### Algunos problemas

### Cálculo de la posterior - Dificultad Computacional

* Las integrales mencionadas anteriormente se pueden calcular de manera numérica
* Los métodos más populares para esto son los de **Markov Chain Monte Carlo (MCMC)**
* Aunque estos métodos típicamente requieren ajuste para lograr una convergencia rápida, avances recientes hacen esto innecesario.

---
class: middle, center, inverse
## Programación Probabilística

---
## Programación Probabilística

Una manera declarativa y sencilla de definir modelos jerárquicos Bayesianos, sin necesidad de resolver el problema matemático específico para cada modelo


```python
import pymc3 as pm

with pm.Model() as model:
    # hyper-parameters
    alpha = 1/data.mean()
    
    # parameters
    tau = pm.DiscreteUniform("tau", lower=0, upper=n_obs)
    lambda1 = pm.Exponential("lambda1", alpha)
    lambda2 = pm.Exponential("lambda2", alpha)
    lambda_i = pm.math.switch(tau &gt;= idx, lambda1, lambda2)
    
    # observations
    obs = pm.Poisson("obs", lambda_i, observed=data)
```

---
background-image: url(resources/advi.png)
background-size: 600px
background-position: 50% 90%
## Programación Probabilística 
### Inferencia

Incluye los métodos computacionales más avanzados para el paso inferencial

```python
with model:
    # Do Inference
    step = pm.advi()
    trace = pm.sample(num_samples, step = step)
```

---
## Programación Probabilística 
### PyMC3

```python
model = pm.Model()
with model:
    # Create Model
    p_coef = Cauchy(0, 2.5)
    repaid = Bernoulli(logit(X * p_coef),
                       observed=logit(repaid_actual))

    # Do Inference
    start = pm.find_MAP()
    step = pm.NUTS()
    trace = pm.sample(num_samples, step, start,
                      progressbar=True)
```

---
## Programación Probabilística 
### Stan

```stan
data {
    int&lt;lower=0&gt; N;
    int&lt;lower=0&gt; N_features;
    matrix[N, N_features] X;
    int&lt;lower=0,upper=1&gt; repaid[N];
}
parameters {
    vector[N_features] p_coef;
}
model {
    vector[N] p;
    p_coef ~ cauchy(0, 2.5);
    p = logit(X * p_coef);
    repaid ~ bernoulli(p);
}
```

---
## Programación Probabilística 
### Anglican

```python
;; Create Model
(defquery gaussian-model [data]
  (let [mu (sample (normal 1 (sqrt 5)))
        sigma (sqrt 2)]
    (doall (map (fn [x] (observe (normal mu sigma) x)) data))
    mu))
  
;; Do Inference  
(def posterior 
  ((conditional gaussian-model :smc :number-of-particles 10) dataset))
  
(def posterior-samples (repeatedly 20000 #(sample* posterior)))
```

---
## ¿Cómo Modelar?
- Tener una o varias preguntas
- Pensar cómo se pudieron haber **generado** los datos
- Escoger **distribuciones** que representen dichos datos
- Modelar **relaciones** entre variables (*e.g.* linealmente, árbol de decisión)
- Modelar parámetros con distribuciones que representen las **creencias iniciales** adecuadamente

---
class: middle, center, inverse
## Por ejemplo...

---
## Ejemplo: Cambio de Media
- *Data*: Número de mensajes de texto recibidos cada día
- ¿Existe un cambio súbito en esta variable?
&lt;img src="slides_xaringan_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---
## Ejemplo: Cambio de Media
- Supongamos que los mensajes se generan de manera aleatoria, según el día
- Una buena distribución para representar esto es la Poisson
&lt;img src="slides_xaringan_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;
- Como el parámetro `\(\lambda\)` indica el promedio, la pregunta puede formularse cómo ¿Existe un cambio de lambda?
- Podemos usar dos parámetros `\(\lambda_1\)` y `\(\lambda_2\)`, para representar estos posibles dos estados
- Lo único que nos falta es un parámetro `\(\tau\)`, el cual representa el día en el cuál ocurre el cambio

---
## Ejemplo: Cambio de Media
- Hay que escoger distribuciones *a priori* para estos tres parámetros
- Suponiendo que no poseemos información previa, una buena idea es escoger la misma distribución para `\(\lambda_1\)` y `\(\lambda_2\)` y una no informativa para `\(\tau\)`. Por ejemplo:
&lt;img src="slides_xaringan_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

- Escogimos una distribución exponencial para `\(\lambda_1\)`, `\(\lambda_2\)`, con (hiper)parámetro `\(\alpha\)` positivo
- La distribución *a priori* para `\(\tau\)` es una discreta uniforme
---
## Ejemplo: Cambio de Media
#### Modelado en PyMC3 (Parámetros)


```python
import numpy as np
import pymc3 as pm

data = np.loadtxt("data/txtdata.csv")
n_obs = len(data)
day = np.arange(n_obs)

# define model
with pm.Model() as model:
    # hyper parameters
    alpha = 1/data.mean()
    
    # parameters
    tau = pm.DiscreteUniform("tau", lower=0, upper=n_obs)
    lambda1 = pm.Exponential("lambda1", alpha)
    lambda2 = pm.Exponential("lambda2", alpha)
    lambda_i = pm.math.switch(day &lt; tau, lambda1, lambda2)
```

---
## Ejemplo: Cambio de Media
#### Modelado en PyMC3 (Observaciones y Predictiva)

```python
with model:
    # observations
    obs = pm.Poisson("obs", lambda_i, observed=data)
    
    # predictive distributions:
    pred1 = pm.Poisson("pred1", lambda1)
    pred2 = pm.Poisson("pred2", lambda2)
  
```

- Después de la inferencia, `pred1` y `pred2` indicaran la distribución predictiva cuando `\(\lambda =  \lambda_1\)` y `\(\lambda = \lambda_2\)`, correspondientemente

#### Inferencia en PyMC3

```python
# perform inference
with model:
    step = pm.Metropolis()
    trace = pm.sample(10000, tune = 5000, step = step)
```
---

## Ejemplo: Cambio de Media
#### Preguntas específicas
- En la variable `trace` se encuentran las muestras tomadas de las distribuciones posteriores y de las predictivas.
- Esta muestra nos permite contestar una gran variedad de 'preguntas'

```python
# Expected L1
print(trace["lambda1"].mean()) # 17.78916798570392
# Expected L2
print(trace["lambda2"].mean()) # 22.669546949779832
# Probability L2 &gt; L1:
print((trace["lambda2"] &gt; trace["lambda1"]).mean()) # 0.9914
# Probability tau = 44
print((trace["tau"] == 44).mean()) # 0.4808
# Probability 20+ messages before tau day
print((trace["pred1"] &gt; 20).mean()) # 0.2478
# Probability 20+ messages after tau day
print((trace["pred2"] &gt; 20).mean()) # 0.6715
```

---
## Ejemplo: Cambio de Media
### Posteriores
&lt;img src="slides_xaringan_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;

---
## Ejemplo: Cambio de Media
### Predictiva(s)
&lt;img src="slides_xaringan_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;


---
## Conclusiones
La **Estadística Bayesiana** provee un *framework* de análisis de datos que propone soluciones para problemas prevalentes en otras técnicas como el *Machine Learning* y la Estadística frecuentista.

La **Programación Probabilística** resuelve algunos de los problemas prácticos relacionados con la inferencia Bayesiana, poniendo al alcance del Científico de Datos estas técnicas, sin necesidad de resolver problemas específicos relacionados a cada modelo.

Tomados juntos, proveen una manera práctica y poderosa de resolver preguntas acerca de incertidumbre y causalidad. En particular, ayudan a disminuir el problema de **sobrecertidumbre** en las predicciones, que puede tener consecuencias catastróficas según la aplicación.

---
class: middle, center, inverse
background-image: url(resources/DataDayMexico.png)
background-size: 256px
background-position: 93% 5%
## ¡Gracias!

twitter: [@arinarmo](https://twitter.com/arinarmo), github: [arinarmo](https://github.com/arinarmo)

### Referencias
[*Bayesian Reasoning and Machine Learning*](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/090310.pdf) - David Barber 

[*Bayesian Methods for Hackers*](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) - Cameron Davidson-Pilon

[*Probabilistic Programming*](http://blog.fastforwardlabs.com/2017/01/30/the-algorithms-behind-probabilistic-programming.html) - Fast Forward Labs

.footnote[ 
  [Repositorio con la plática](http://github.com/arinarmo/love_uncertainty): arinarmo/love_uncertainty 
]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
